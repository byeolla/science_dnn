{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in = np.loadtxt(fname='./test-score.csv', delimiter=',')\n",
    "x_train = torch.from_numpy(data_in[:, 0:3]).float()             # (N, 3)\n",
    "y_train = torch.from_numpy(data_in[:, 3]).unsqueeze(1).float()  # (N, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    #__init__(): 객체가 갖는 속성값을 초기화하는 역할 -> 객체가 생성될 때 자동으로 호출\n",
    "    # super()호출 >>>> 오버라이딩,  nn.Module 클래스의 속성들을 가지고 초기화 \n",
    "    def __init__(self, W, b):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "        self.linear.bias = nn.Parameter(b, requires_grad=True)\n",
    "        self.linear.weight = nn.Parameter(W.T, requires_grad=True)\n",
    "\n",
    "    #forward() :모델이 학습데이터를 입력받아서 forward 연산을 진행 -> 객체를 데이터와 함께 호출하면 자동으로 실행\n",
    "    # forward 연산: H(x)  식에 입력 x로부터 예측된 y를 얻는 것\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.zeros((3, 1))\n",
    "b = torch.zeros(1)\n",
    "# model.parameters([W, b])\n",
    "model = LinearRegressionModel(W, b)\n",
    "# model.parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
    "nb_epochs = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/100000 W: (0.26151597, 0.26294398, 0.26934156), b: 0.003 Cost: 26811.960938\n",
      "Epoch 10000/100000 W: (0.38032684, 0.5210467, 1.112572), b: -0.005 Cost: 6.110940\n",
      "Epoch 20000/100000 W: (0.35797518, 0.5294029, 1.1263276), b: -0.021 Cost: 6.096858\n",
      "Epoch 30000/100000 W: (0.3561641, 0.53038293, 1.12733), b: -0.038 Cost: 6.094028\n",
      "Epoch 40000/100000 W: (0.3560846, 0.53047836, 1.1275129), b: -0.055 Cost: 6.091289\n",
      "Epoch 50000/100000 W: (0.3560721, 0.53054136, 1.127662), b: -0.071 Cost: 6.088572\n",
      "Epoch 60000/100000 W: (0.35606483, 0.5305922, 1.127817), b: -0.087 Cost: 6.085886\n",
      "Epoch 70000/100000 W: (0.35606423, 0.5306378, 1.1279699), b: -0.104 Cost: 6.083202\n",
      "Epoch 80000/100000 W: (0.3560635, 0.5306838, 1.1281216), b: -0.120 Cost: 6.080553\n",
      "Epoch 90000/100000 W: (0.356064, 0.53072816, 1.1282735), b: -0.136 Cost: 6.077927\n",
      "Epoch 100000/100000 W: (0.35606432, 0.530774, 1.1284227), b: -0.152 Cost: 6.075311\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    # Compute H(x)\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    # Compute the cost with MSE\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "    # Update H(x)\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    # print epoch and cost for every 20 epochs\n",
    "    \n",
    "    if epoch % 10000 == 0:\n",
    "        params = list(model.parameters())\n",
    "        W = params[0].detach().numpy()\n",
    "        b = params[1].item()\n",
    "        print('Epoch {:4d}/{} W: {}, b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, tuple(*W), b, cost.item()\n",
    "        ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[152.9338]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "# Put the test input\n",
    "new_var = torch.FloatTensor([[73, 80, 75]])\n",
    "# Get the prediction value.\n",
    "pred_y = model(new_var)\n",
    "print(pred_y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('science_dnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0f2ae45ca5b13b9dba64e90d12e7a2d503c99b3d3d62896f22c1678fa3ef761"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
